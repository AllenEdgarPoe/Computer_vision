{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU-directional.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQp5JJ6dydxYgFMDFA5NWs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllenEdgarPoe/Computer_vision/blob/master/GRU_directional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRHjdXHIdi_x",
        "colab_type": "code",
        "outputId": "45313b83-c5cd-48cd-ba0d-0479cb7e12ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0WDaak5Toya",
        "colab_type": "text"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP6_IllGTrTC",
        "colab_type": "code",
        "outputId": "1c002f54-3bed-433e-a514-b0e2834358a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "!pip3 install torch unidecode\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.5)\n",
            "Installing collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO0qOi6yeZ-D",
        "colab_type": "code",
        "outputId": "5eebf03e-aaa7-4e43-9cfa-3cd076dcd96f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "num_epochs = 10000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "chunk_len = 200\n",
        "embedding_size = 150\n",
        "hidden_size = 100\n",
        "batch_size =1\n",
        "num_layers = 2\n",
        "lr = 0.002\n",
        "\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print('num_chars = ', n_characters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKdjR31Mez1t",
        "colab_type": "text"
      },
      "source": [
        "### Get Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuvMfJ77cvoI",
        "colab_type": "code",
        "outputId": "68af39ae-ffc8-4ef1-8bbc-b5fecf712d09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "file = unidecode.unidecode(open(\"./gdrive/My Drive/data/linux.txt\").read())\n",
        "file_len = len(file)\n",
        "print(\"file의 길이는: \", file_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file의 길이는:  34167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_TkHQB4Tyon",
        "colab_type": "text"
      },
      "source": [
        "###Functions for text processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVT4XClZT0Qf",
        "colab_type": "text"
      },
      "source": [
        " 1. Random Chunk: 랜덤하게 200개 charcter 추출하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvajVurqT2lr",
        "colab_type": "code",
        "outputId": "585b93dd-7341-4f49-e753-585d895d7c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "holding bfqd->lock. A blkg_lookup performed with\n",
            "\t * bfqd->lock held then returns a fully consistent blkg, which\n",
            "\t * remains consistent until this lock is held.\n",
            "\t *\n",
            "\t * Thanks to the last fact, and to \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWmgFAUeT4Qq",
        "colab_type": "text"
      },
      "source": [
        "2. Character to tensor: char를 숫자 텐서로 표현하기.. 앞에서 100개 all printable 한 character를 구했으니까 0~100 사이 숫자로 표현될 것. index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouEJBF-VT5tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()       #먼저 100개의 0으로 구성된 텐서로 만들자\n",
        "  for c in range(len(string)):\n",
        "    tensor[c] = all_characters.index(string[c])\n",
        "  return Variable(tensor).cuda()     #tensor로 만들어주기 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bs8KxlDT7bM",
        "colab_type": "text"
      },
      "source": [
        "3. Chunk into input & label: 랜덤하게 구한 chunk를 input과 label로 나누기. training dataset을 만들기 위해.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ROfe9_T9K7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_training_set(): \n",
        "  chunk = random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrX0nFNqT_Dg",
        "colab_type": "text"
      },
      "source": [
        "### Model&Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdi101_FUAjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding_size = embedding_size\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.GRU(embedding_size,hidden_size,num_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        out = self.encoder(input.view(1,-1))\n",
        "        out,hidden = self.rnn(out,hidden)\n",
        "        out = self.decoder(out.view(batch_size,-1))\n",
        "        \n",
        "        return out,hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = Variable(torch.zeros(self.num_layers, batch_size, hidden_size)).cuda()\n",
        "        return hidden\n",
        "    \n",
        "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers=2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRdtPeWQUB1s",
        "colab_type": "code",
        "outputId": "352b7168-a452-4d65-8546-7da9a5a78af5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "inp = char_tensor(\"A\")\n",
        "print(inp)\n",
        "hidden = model.init_hidden()\n",
        "print(hidden.size())\n",
        "\n",
        "out,hidden = model(inp,hidden)\n",
        "print(out.size())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([36], device='cuda:0')\n",
            "torch.Size([2, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4rqV7bFUGfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIVE_Z0bUIXG",
        "colab_type": "text"
      },
      "source": [
        "### Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ44fGt9UJvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    start_str = \"b\"\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden = model.init_hidden()\n",
        "    x = inp\n",
        "\n",
        "    print(start_str,end=\"\")\n",
        "    for i in range(200):\n",
        "        output,hidden = model(x,hidden)\n",
        "\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        predicted_char = all_characters[top_i]\n",
        "\n",
        "        print(predicted_char,end=\"\")\n",
        "\n",
        "        x = char_tensor(predicted_char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73eDTu0mULIW",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhN9zaExUR95",
        "colab_type": "code",
        "outputId": "10b6352d-2a88-4161-cb65-3772700b7fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loss_list = []\n",
        "for i in range(num_epochs):\n",
        "    total = char_tensor(random_chunk())\n",
        "    inp = total[:-1]\n",
        "    label = total[1:]\n",
        "    hidden = model.init_hidden()\n",
        "\n",
        "    loss = 0\n",
        "    optimizer.zero_grad()\n",
        "    for j in range(chunk_len-1):\n",
        "        x  = inp[j]\n",
        "        y_ = label[j].view(-1)\n",
        "        y,hidden = model(x,hidden)\n",
        "        loss += loss_func(y,y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n\",loss/chunk_len,\"\\n\")\n",
        "        test()\n",
        "        print(\"\\n\\n\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " tensor(4.5972, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bjc`N<b>r|A`-{dKRii9UQcKZY}\n",
            "\u000b7n?TQobm<rqH@j}h\fA>_8 3m?o6V)-+c)LQY)zw_`#kv'ae{vzskhN&)bsS&s+v~65{tI\n",
            "E(ieE/%&zC~bf}8+m']kGidv{wkDN;k]mc$o\\\"p6if\n",
            "W27W}MhJaut}q#u~w}id'K|wiR5%y\\p4vv-=mds;VyYFr'=rlC,FkI]}`5}\n",
            "\n",
            "\n",
            "\n",
            " tensor(1.6960, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bgipd_enled;\n",
            "\tests_he   lom unlck t bfq_rents ast stoe);\n",
            ">een;\n",
            " *bfq_Krtialent bfq_&ict *->ill = bfqg_pctoup;\n",
            "\t\tbfq_bfqg_storu->eiataenthI hc *statattag)\n",
            "\n",
            "thny_trie_bqgs,\n",
            "\t= bfqq_pinty_tatiseon d  it(s\n",
            "\n",
            "\n",
            "\n",
            " tensor(1.9091, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg) {\n",
            "\trooup *blkg_que) {\n",
            "\tblkg_prbin_cololic the bfqd,\n",
            "\t\t * pro_crlass = woo_pd_queseue(st\n",
            "\t.licy the the tles\n",
            "\tlcget_winight mand (int_the, Tfreouns pliolw(bfqq_pq_blkcg_proup *blkg_rows_uflig_wrou\n",
            "\n",
            "\n",
            "\n",
            " tensor(1.2422, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bRfqq);\n",
            "\t\t\treturn blkcg, fold bfqg_stat_blkcg_pd_wait_tivate. it serivericy_sure the all = 0;\n",
            "}\n",
            "\n",
            "\tblkg_roup *stats_blkcg_pit_stat, &stats->time);\n",
            "\tbacg_bfqg_stat_squeue(struct blkg_pd_maty_to_bfqq,\n",
            "\t *\n",
            "\n",
            "\n",
            "\n",
            " tensor(1.4182, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_stat_reset(&blkg_stats_entity(bfqg, stats->arget_rexit(bfqd);\n",
            "\t\treturn bfq_group *bfqg_ditighe il = wint bfq_group( * ove hallock an);\n",
            "\tblkg_swat_reeamy_time);\n",
            "\tblkg_set_to_blkg_print_blkg_stat_re\n",
            "\n",
            "\n",
            "\n",
            " tensor(1.7521, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_print_offqg_stat_reset(&stats->stats(struct bfq_group *stats *struct bfqg_print_rwstats = stats_update_time, unsic oftes mapd laes igned it thil stats * thite and the to thidle the aling om the il\n",
            "\n",
            "\n",
            "\n",
            " tensor(1.7437, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bwg)\n",
            "{\n",
            "\tf (!bfqg->blkcg(struct bfq_entity\n",
            "\t\t\t\t * pater\t * @dostens constatic the entities of the bsecurentity *bfqd,\n",
            "\tstruct bfqg_stats->set_recursive.;\n",
            "\t\tblkg_axio_bfqg),\n",
            "\t\tstruct bfq_rews_aux(&to_bfq\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.7996, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_prfill_setals)) {\n",
            "}\n",
            "\n",
            "void bfqg_stats *struct bfq_group *bfqg->struct bfqg_stats *stats *stats *stats *scheding now = bfqd: the parent: to parent 0\n",
            "\t\t\t  struct bfq_group *bfqg)\n",
            "{\n",
            "\tblkcg_policy_bfqq\n",
            "\n",
            "\n",
            "\n",
            " tensor(1.2848, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bkg_queue_xatime(struct bfq_group *bfqd);\n",
            "\tstruct bfq_group *bfqg)\n",
            "{\n",
            "\tstruct blkcg_print_stat_init(&stats->avg_queue,\n",
            "\t\t\t\t\t\t\t\t\t\t   struct bfqg->entity;\n",
            "\n",
            "\tivate *entity)\n",
            "{\n",
            "\t\treturn &blkcg_prin_time;\n",
            "\t\te\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.7810, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkcg_policy_files, op, &bfqg->start_untime,\n",
            "\t\t\t  struct bfqg_print_time, &from->avg_queue_size_sum);\n",
            "\tblkg_group(struct blkg_queue,\n",
            "\t * the blkg_rwstat_tor, gfp) = &blkcg_policy_bfqg, 0);\n",
            "}\n",
            "\n",
            "static st\n",
            "\n",
            "\n",
            "\n",
            " tensor(1.2382, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkcg_policy(bfqg);\n",
            "\t\tbfqg_stats_idle_time),\n",
            "\t\t.private = \"bfqq_service_time);\n",
            "\tbfqg_stat_set(bfqg);\n",
            "\n",
            "\tbfqg;\n",
            "\tblkg_gat_bio_set(&stats->group(struct bfq_group *bfqg = cgroup put or group now = cgrptor t\n",
            "\n",
            "\n",
            "\n",
            " tensor(1.2450, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg)\n",
            "{\n",
            "\tentity->J#inc_bfqcg_gq_group_data *pd)\n",
            "{\n",
            "\tfor (bfq_cpd_alloc_cftype, pd_to_bfqd(bi&);\n",
            "\tentity->blkg_stat_add_aux(&to->empty->blkcg_stat_exit(&stats->empty_time\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tstruct bfq_group *\n",
            "\n",
            "\n",
            "\n",
            " tensor(1.0183, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_prfill_rwstat_recursive(struct bfq_entity = entity = offsetof(struct bfq_find_set_init = struct bfq_queue);\n",
            "\n",
            "\tblkg_stat_recursive_sum,\n",
            "\t\t\t\t  serial_nr(bik);\n",
            "\tstruct bfq_group.\n",
            " * @ctivea.\n",
            " * @bfqd\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.5430, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg->stats = &bfqg->sched_data;\n",
            "}\n",
            "\n",
            "static void bfqg_stats, struct bfq_entity *entity->parent;\n",
            "\n",
            "\treturn PRNSEPE; Aint ock for then blkg (instruct blkg_policy_data *bfq_group *bfqg);\n",
            "\tstruct bfq_group *\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3632, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkcg_queue_size(struct blkcg_gq *blkcg)\n",
            "{\n",
            "\tstruct blkcg)\n",
            "{\n",
            "\tstruct blkcg_prlist_stat_recursive,\n",
            "\t\t\t\t\t\t   &bfqg);\n",
            "\t\tblkg_stat_exit((st->weight->sched_data;\n",
            "\tblkg_stat_add_aux(&teruct bfq_group *bfqg = \n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2948, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_print_stat_recursive(struct seq_file schedule bfqg and bfq_group, stats.merged);\n",
            "\tbfqg_stats_cleeac(struct bfq_group primate to the stats shour entity on the conting a conted blkg async_bfqq)->idl\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.9752, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg->stats, BFQG_stats_##name(struct seq_file *sf,\n",
            "\t\t\t\t\t\tstruct bfqg, int off);\n",
            "\tif (!bfqg->stats);\n",
            "\tstruct blkg_rwstat_recursive,\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\tstruct bfq_entity = bfq_bic_update_get_queue, &blkcg_po\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.7139, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqq_move(stroc4 void bfq_group(blkg);\n",
            "}\n",
            "\n",
            "static void bfq_pd_io_move, &from->active);\n",
            "\tif *\n",
            "\t * blkg is consistened with then the group als been neces.\n",
            " * @st: the sret to of the new val beiond alke st\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.4493, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd->in_difq_cupd);\n",
            "}\n",
            "\n",
            "void bfq_group, stats.merged),\n",
            "\t\t.seq_show = bfqg_print_stat_init(&stats->idle_time);\n",
            "\tblkg_stat_init(&stats->queued);\n",
            "\tblkg_stat_init(&stats->group_wait_time);\n",
            "\tblkg_stat_init(\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.5116, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg) = bfqg_print_rwstat_exit(&stats->avg_queue_size_sum);\n",
            "\n",
            "\tif (entity->sched_data) {\n",
            "\t\t/* Make samples acth\n",
            "\t\t * the lock ic (unsigned for = bfq_entity_update_alloc(struct bfq_data *bfqd, struct of \n",
            "\n",
            "\n",
            "\n",
            " tensor(0.6968, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd->lock, for the bfqg and in functions on the scheduler the blkg_lookup protected with the path the only that bfq_bic_update_avg_queue_size_samples);\n",
            "\tblkg_stat_reset(&stats->idle_time, &from->rest;\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.6805, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_put(bfqg) : NULL;\n",
            "\n",
            "\tgupt seq_file *sf, void bfqg_stats_update_dequeue(struct blkcg_gq *blkg;\n",
            "\n",
            "\tif * the prio_changed finslisssandling an adletigath on a tinsigned int op)\n",
            "{\n",
            "\tstruct bfq_group *bfqg\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.5041, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_stats_mark_empty(stats);\n",
            "}\n",
            "\n",
            "void bfq_blkg_rwstat_reset(&stats->queued\",\n",
            "\t\t\t.private = offsetof(struct bfq_group *bfqg) { }\n",
            "void bfqg_stats_init(&stats->wait_time);\n",
            "\tblkg_rwstat_reset(&stats->time)\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3334, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_leaf_entity(bfqg);\n",
            "}\n",
            "\n",
            "static void bfq_bfqq, struct bfq_group *bfqg,\n",
            "\t\t.seq_show = bfqg_print_stat_init(&stats->avg_queue,\n",
            "\t\t\t\t\t struct bfq_group *bfqg;\n",
            "}\n",
            "\n",
            "struct bfq_group *bfqg, use and the and f\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.6122, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_rwstat_recursive_samples,\n",
            "\t\t\t\t\t\t\t\t\t\t\t   finit - deentity move. OO may this\n",
            "\t * blkg data for more which mor us and will/en al active\n",
            "\t\t\t\t\t * blkg_put for the origid in the\n",
            " * blkg_policy_bfq);\n",
            "}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd->root_group;\n",
            "}\n",
            "\n",
            "struct bfq_group, stats = &bfqg->stats;\n",
            "\n",
            "\tif (!bfqg) - rooks are deturn blkg.\n",
            "\t * This emplety - move bfqg_stats_empty(stats));\n",
            "\tstruct bfq_group, stats.dequeue))\n",
            "\t\tbfq_bfqq_expire\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd, bfqgd->weight;\n",
            "\n",
            "\tblkg_stat_exit(&stats->time),\n",
            "\t\t.seq_show = bfqg_print_stat_add(&stats->group_wait_time),\n",
            "\t\t.seq_show = bfqg_print_stat_init(&stats->empty_time);\n",
            "\tblkg_stat_exit(&stats->avg_queu\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.6662, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_stats_entity(struct blkg_policy_data *bfq_cpd_init_fn\t\tin put */\n",
            "\n",
            "\treturn bfq_blkg_lookup_bfqg(bfqd;\n",
            "}\n",
            "\n",
            "void bfqg_stats_start_time(struct bfq_group *bfqg) { }\n",
            "void bfqg_stats_empty(stats);\n",
            "}\n",
            "\n",
            "stat\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.5602, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_stats_empty(stats);\n",
            "\n",
            "\treturn bfqg->root_group;\n",
            "\n",
            "\tif (bfqg_stats_empty(stats, &NFIAG_FLAG_FNS(time))\n",
            "\t\tblkg_rwstat_addd(&bfqg->stats);\n",
            "}\n",
            "\n",
            "static int bfqg_parent(struct bfq_group *bfqg) { }\n",
            "void bfq\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.7230, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg);\n",
            "\n",
            "\tbfqg_stats_update_id(struct blkcg_gq *blkg_queue of BFQ. I/\n",
            "\t/*\n",
            "\t * Make sure before we\n",
            "\t * service any we\n",
            "\t * bfq_bic_update_idle_tree(struct bfq_group *bfqg)\n",
            "{\n",
            "\tstruct bfq_group *bfqg)\n",
            "{\n",
            "\tst\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.5982, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_put(bfqg);\n",
            "\t}\n",
            "\n",
            "\t/* start be called with the scheduler lock helde blkg objects associated blkg as\n",
            "\t * _remove bfqg does being to this bic uinsis\n",
            " * its old be called with the entity ont it be calle\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.4081, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd->root_group);\n",
            "}\n",
            "\n",
            "void bfq_init_entity_ond(struct bfq_get_queues WRNEGHT_NN= /*\n",
            "\t\t * the bfqg_stats_update_completion(struct bfq_data *bfqg)\n",
            "{\n",
            "\tstruct bfq_group *bfqg, unsigned int on.\n",
            "\t\t *\n",
            "\t\t\t\t * \n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg);\n",
            "\n",
            "\treturn;\n",
            "\n",
            "\t/*\n",
            "\t * we nave long now, we al may need false, false);\n",
            "\tbfqg->bfqgd(blkg_to_blkg(bfqg);\n",
            "\n",
            "\treturn;\n",
            "\n",
            "\tnow */sere wait a need ation;\n",
            "\n",
            "\tstats->start_empty_time(struct bfq_group *bfqg) { \n",
            "\n",
            "\n",
            "\n",
            " tensor(0.8021, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd, bfqq));\n",
            "\t}\n",
            "\t}\n",
            "\n",
            "\tstruct bfq_group *bfqg)\n",
            "{\n",
            "\tstruct bfqg_stats *stats = &bfqg->stats.deques, pd->queue);\n",
            "}\n",
            "\n",
            "static int bfqg_print_stat,\n",
            "\t},\n",
            "\n",
            "\t/* statistics, has not for the\n",
            "\t\t * bfqg->pd will be it\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd, int node)\n",
            "\t\treturn 0;\n",
            "}\n",
            "\n",
            "static struct bfq_group_data *cpd)\n",
            "{\n",
            "\tstruct bfq_group_data *bfq_cpd_alloc_cgroup(struct bfq_group *bfq_find_set_group(bfqq(bfqd)->q_group_wait_time, &from->merget);\n",
            "\n",
            "\t\t\t\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg->bfqd->queue, &blkcg_policy_bfq,\n",
            "\t\t\t  seq_css(sf)),\n",
            "\t\t\t\t  bfqg->rq_pof(ro) {\n",
            "\t\treturn 0;\n",
            "}\n",
            "\n",
            "static int bfqg_stats_reset(&stats->avg_queue_size_sum;\n",
            "}\n",
            "\n",
            "voidler\n",
            "\t * to the invokes be asynchins any i\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqq->new_ioprio;\n",
            "\t\tif (entity->orig_io_remove(struct bfq_data *bfqd,\n",
            "\t\t\t\t                 struct bfqg_stats *stats->flags = CFNYE_ROT,\n",
            "\t},\n",
            "\t{\n",
            "\t\t.name = \"bfq.weight\",\n",
            "\t\t.flags = CFTYPE_NOT_ON_ROT,\n",
            "\t\t.s\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.7752, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd->blkg_stat_read(&prom->wait_time);\n",
            "\tblkg_stat_reset(&stats->time);\n",
            "}\n",
            "\n",
            "static void bfqg_stats_update_io_merged(struct bfq_group *bfqg, struct bfq_entity *entity = &bfqg->time);\n",
            "\tbfqg_stats_mark_##n\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2822, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg, false);\n",
            "\tblkg_stat_add_aux(&to->avg_queue_size(struct bfq_data *bfqd,\n",
            "\t\t\t\t              struct bfq_data *blkcg_to_bfqgd(blkcg_to_blkg(bfqg);\n",
            "}\n",
            "\n",
            "void bfq_bic_change_cgroup on pd) to mist being and\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.4163, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_to_bfqg(pd);\n",
            "\n",
            "\tstruct bfq_group *bfqg)\n",
            "{\n",
            "\tbfqg_put(struct bfq_queue *bfqq: to make sure that the referent group.\n",
            " * @bic: the bo co may the root group.\n",
            " * @st: the queue *bfqq,\n",
            "\t\t\t\t\t\t    struct bf\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.5968, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_to_pd_free(cpd(struct bfq_group_data *bfqd,\n",
            "\t\t\t\t\t struct blkg_rwstat_init(&stats->queued))\n",
            "\t\tbfqg_stats_update_io_remove(struct bfq_data *bfq_cpd_alloc_fn\t\t= bfq_cpd_alloc,\n",
            "\tBFQG_stats_empty,\n",
            "\t\t.p\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.9724, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd->queue_size_samples);\n",
            "\tbfqg_stats_update_avg_qoue_fre(bfqd, blkcg);\n",
            "\tbfqg_stats_set_start_idle_time(struct bfq_data *bfqd = bfqd->root_group;\n",
            "}\n",
            "\n",
            "struct blkg_rwstat_add(&stats->start_group_wait_tim\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3972, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfq_entity = bfqg_print_stat,\n",
            "\t},\n",
            "\t{\n",
            "\t.fne\n",
            "\t\t\t\t = bfq_pd_free(struct bfq_group *bfqg = blkg_stat_add_aux(&to->empty_time,\n",
            "\t\t\t\t     now - stats->start_idle_time);\n",
            "\tblkg_stat_add(&stats->service_tree(ent\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2101, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg = pd_to_bfqg(pd);\n",
            "\tbfqg_stats_empty(bfqg);\n",
            "\n",
            "\t\t\tif (time_after64(now, off)\n",
            "{\n",
            "\tu64 sum = blkg_rwstat_recursive(struct seq_file *sf,\n",
            "\t\t\t\t\t struct bfq_data *bfqd,\n",
            "\t\t\t\t\t\t\t\t\t struct bfq_entity *entity =\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.4414, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqq = bic_to_bfqq(bic);\n",
            "\n",
            "\tblkg_stat_add_aux(&to->idle_urn;\n",
            "\t}\n",
            "\n",
            "\t\tbfq_pof_bfqq(bfqd, bfqq);\n",
            "\t\t/*\n",
            "\t\t * This should group has an tree with the queues reuct blkg.\n",
            "\t *\n",
            "\t * Ot an\n",
            " * whe\n",
            "\t * read long findin\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqq - move - move of @st. Ass: the weight;\n",
            "\t\tif (time_after64(io_start_time, unsigned int op) {\n",
            "\t\tbfqq->ioprio_class = bfq_cpd_init,\n",
            "\t.cpd_free (i = 0;\t\t\t\t\t\tif (time_after64(io_start_time, unsigned in\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.4936, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg->bfqd;\n",
            "\tstruct bfq_group *bfqg)\n",
            "{\n",
            "\tbfqg->entity.new_weight = curr_bfqg)\n",
            "{\n",
            "\tstruct bfqg_stats *to t: NULL;\n",
            "}\n",
            "\n",
            "struct bfq_group *bfqg)\n",
            "{\n",
            "\tstruct bfq_group, stats.merged),\n",
            "\t\t.seq_show = blkg_print_st\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqq->entity;\n",
            "\tentity->sched_data = &bfqg->sched_data.serial_nr;\n",
            "\n",
            "\t\tif (!to 1 != 0; i    */\n",
            "\tbfqg->ref++;\n",
            "}\n",
            "\n",
            "void bfq_io_cleares_recursive,\n",
            "\t},\n",
            "\t{\n",
            "\t\t.name = \"bfq.io_merged_recursive\",\n",
            "\t\t.private = offs\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1929, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd->root_group) {\n",
            "\t\tstruct bfq_group *bfqg)\n",
            "{\n",
            "\tstruct bfq_group *bfqg)\n",
            "{\n",
            "\tstruct bfq_group *bfqg)\n",
            "{\n",
            "\tstruct bfq_group *bfqg = blkg_to_bfqg(bfqd->queue))\n",
            "\t\tbfq_queue lock is being held, here we canged\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.6338, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkcg_gq *pblkcg: the blkg also in bfq_blkg_file *sf, void int off)\n",
            "{\n",
            "\tstruct bfq_group *bfqg)\n",
            "{\n",
            "\tstruct bfqg_stats *stats)\n",
            "{\n",
            "\tblkg_rwstat_exit(&stats->merged);\n",
            "\tblkg_rwstat_add_aux(&parent->my_entity;\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.4644, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqq == bfqq(bic, 1);\n",
            "\n",
            "void bfqg_stats_empty(stats);\n",
            "}\n",
            "\n",
            "/* terminates sure\n",
            "\t\t\t * stats for the scheduler ssistass.service taks to that protects in bfqg->entity) {\n",
            "\t\treturn __blkg_prfill_u64(sf, pd, sum\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1495, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_parent->my_entity), entity.prio.h>\n",
            "#include <linux/blkdev.h>\n",
            "#include <linux/blkdev.h>\n",
            "#include <linux/blkg = bfq_io_set_weight(struct blkcg_gq *blkg;\n",
            "\n",
            "\t/*\n",
            "\t * General Public License, vientirst bf\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3591, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_to_bfqgd(cpd));\n",
            "}\n",
            "\n",
            "static u64 bfqg_prfill_avg_queue_size(st);\n",
            "\n",
            "\treturn blkg_to_bfqg(pd);\n",
            "\tstruct bfq_group *bfqg = pd_to_bfqg(pd);\n",
            "\n",
            "\treturn GFP_NNFLEA; i++)\n",
            "{\n",
            "\tstruct blkcg_policy_data *pd, int of\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2050, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_to_blkg(bfqg)->parent;\n",
            "\n",
            "\treturn pd_to_blkg(bfqg)->parent;\n",
            "\t}\n",
            "\tentity->sched_data.service_time);\n",
            "\tblkg_stat_add_aux(&to->avg_queue_size_sum);\n",
            "\tblkg_stat_exit(&stats->idle_time);\n",
            "\tbfqg_stats_empty(s\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd->root_group) {\n",
            "\t\t\t     bfqg_prfill_sectors(struct seq_file *sf, void *v)\n",
            "{\n",
            "\tblkg_stat_reset(&stats->time);\n",
            "\t\tblkg_stat_reset(&stats->time);\n",
            "\tblkg_stat_add_aux(&to->service,\n",
            "\t.cpd_init_fn\t\t= bfq_pd\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.5313, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg->sched_data = &bfqg->sched_data;\n",
            "\t/* pin down blk-cgroup is are cost of a still new_weight = (unsigned short)val;\n",
            "\t/* First be clicity or the blkg_free of the following to a bfq_entity *entity = s\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd->lock it new_weight = (unsigned long)&blkcg_policy_bfq, queueue, &blkcg_policy_bfq, 0, unef(struct bfq_group, stats.time),\n",
            "\t\t.seq_show = bfqg_print_stat,\n",
            "\t},\n",
            "\t{\n",
            "\t\t.name = \"bfq.sectors\",\n",
            "\t\t.seq_sho\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_stats_update_completion(struct bfq_data *bfqd)\n",
            "{\n",
            "\tstruct blkcg_policy_data *pd,\n",
            "\t\t\t        unsigned int op)\n",
            "{\n",
            "\tblkg_stat_init(&stats->merged, gfp) ||\n",
            "\t    blkg_rwstat_init(&stats->merged, gfp) ||\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_and_blkg_get(bfqg);\n",
            "\n",
            "\tif (!RB_EMPTY_ROOT(&st->active;\n",
            "\tstruct bfq_group_data, pd) : NULL;\n",
            "}\n",
            "\n",
            "static struct bfq_group, stats.merged),\n",
            "\t\t.seq_show = bfq_init_fn\t\t= bfq_pd_reset_stats_mprete_cnread(s\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg;\n",
            "\tblkg_rwstat_reset(&stats->avg_queue_size_sum, &from->avg_queue_size_sum, = bfq_io_set_weight_legacy(oo_start_time,\n",
            "\t\t\t\t  struct bfq_group *bfqg, unsigned int op) { }\n",
            "void bfqg_stats_xfirq(&blkcg\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.4052, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd->root_group;\n",
            "}\n",
            "\n",
            "static struct bfq_group *bfqg = pd_to_bfqg(pd);\n",
            "\n",
            "\treturn __blkg_prfill_u64(sf, pd, sum >> 9);\n",
            "}\n",
            "\n",
            "static struct blkcg_gq *blkg does not new\n",
            "\t * scheduler lock, to exited that the lo\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1663, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqgd(struct bfq_group *bfqg;\n",
            "\n",
            "\t\tbfqg and its of the\n",
            "\t * dist in the execution\n",
            "\t\t * scheduler has trals to its hooks are execution on the bfqg, to it help is not need to the hopf at, recursive, the\n",
            "\t *\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.4020, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_to_blkg(pd))\n",
            "\t\t\tbfqg_stats_set_start_idle_time(struct blkg_policy_data *pd, int off);\n",
            "\treturn ret;\n",
            "\n",
            "\treturn cpd ? spine_fron protectes\n",
            "\t * seen in that so that the execution makersity the new valu\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2239, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqgd = 0;\n",
            "\tspin_unlock_irqresive,\n",
            "\t},\n",
            "\t{\n",
            "\t\t.name = \"bfq.io_queued\",\n",
            "\t\t.seq_show = bfqg_print_stat,\n",
            "\t},\n",
            "\t{\n",
            "\t\t.name = \"bfq.sectors_recursive_free = bfqq->new_ioprio = bfqq->new_ioprio_class;\n",
            "\t/* If bfqq\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_stat_exit(&stats->idle_time, gfp) ||\n",
            "\t    blkg_stat_exit(&stats->idle_time, gfp) ||\n",
            "\t    blkg_stat_add_aux(&from->idle_time);\n",
            "\tblkg_stat_exit(&stats->group_wait_time);\n",
            "\tblkg_put(struct bfq_group *\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3639, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bio_shouldachral_nr;\n",
            "\n",
            "\t/* see comments in bfq_bic_uxbq_queues(bfqd;\n",
            "\tbfqg_put(bfqg_to_blkg(bfqg));\n",
            "}\n",
            "\n",
            "void bfqg_stats_update_completion(struct bfq_service_tree *st)\n",
            "{\n",
            "\tstruct blkcg_gq *pd_to_bfqg(pd);\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_rwstat_init(&stats->ve_se>serig_weight_legacy);\n",
            "\t\t\t/*\n",
            "\t\t * Make sum = blkg_rwstat_recursive_sum(pd_to_blkg(&bfqg->pd);\n",
            "}\n",
            "\n",
            "static int bfqg_print_rwstat_recursive,\n",
            "}\n",
            "#endanty, BFQ_WEIGHT_LEGACY_DFL;\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.4496, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg = blkg_lookup perfill_sectors(struct seq_file *sf, void *v)\n",
            "{\n",
            "\tblkcg_print_blkgs(sf, css_to_blkcg(seq_css(sf)),\n",
            "\t\t\t  bfqg_prfill_sectors(struct seq_file *sf, void *v)\n",
            "{\n",
            "\tblkcg_print_blkgs(sf, css_\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3240, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_and_blkg_get(bfqg);\n",
            "\n",
            "\tblkg_put(struct bfq_group *bfqg) { }\n",
            "void bfq_init_entity(bfqd, sync_bfqq->ioprio_clacppd_to_bfqg(bfqd->queue->blkg_list, q_node) {\n",
            "\t\tstruct bfq_group *bfqg = blkg_to_bfqg(pd\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_stats_update_group_wait_time(struct bfq_group *bfqg)\n",
            "{\n",
            "\t/* see comments in bfq_bic_update_cgroup for why refcountistess, any false, false, false);\n",
            "\tentity->sched_data = &bfqg->sched_data;\n",
            "}\n",
            "\n",
            "stati\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfq_io_set_weight_legacy(struct bfq_group *bfqg, *pd)\n",
            "{\n",
            "\tstruct bfq_group *bfqg = pd_to_bfqg(pd);\n",
            "\n",
            "\tbfq_deactivate_bfqq(bfqd, sync_bfqq->entity;\n",
            "\tentity->sched_data = &blkcg_policy_bfq, seq_cft(sf)->pr\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2061, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_lookup handlers is now = sched_clock();\n",
            "\tblkg_stat_add(&stats->queued, gfp) ||\n",
            "\t    blkg_rwstat_init(&stats->avg_queue_size_sum, gfp) ||\n",
            "\t    blkg_stat_init(&stats->time);\n",
            "\tblkg_stat_reset(&stats-\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkcg_print_rwstat_recursive,\n",
            "\t},\n",
            "\t{\n",
            "\t\t.name = \"bfq.avg_queue_size\",\n",
            "\t\t.write_u64 = \"bfq.io_merged_recursive\",\n",
            "\t\t.private = offsetof(struct bfq_group, stats.merged),\n",
            "\t\t\t  &blkcg_policy_bfq, 0,\n",
            "\t\t\t   &b\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1306, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqgd;\n",
            "\n",
            "\tbfqg = bfqd->root_group) { }\n",
            "void bfqg_stats_update_idled (in\n",
            "\t\t\t\t * stet bfqd->lock held for\n",
            "\t * BFQ. As a bfq_group hierarchy\n",
            " * by allowing the policy_group *bfqg)\n",
            "{\n",
            "\treturn g_rwstats_updat\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg dow's in bfq_bic_update_cgroup one move queue this\n",
            "\t * blkg_free of the code\n",
            "\t\t\t * diffell that the fully consistent blkg (whl be called under the scheduler lock, to make sure that the new value h\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_print_stat_ios,\n",
            "\t},\n",
            "\t{\n",
            "\t\t.name = \"bfq.io_merged, gfp) || likely(!bfqg) { }\n",
            "void bfqg_stats_end_empty_time(struct seq_file *sf,\n",
            "\t\t\t\t\t struct blkg_policy_data *pd, int off)\n",
            "{\n",
            "\tu64 sum = a *pd,\n",
            "\t\t\t\t \n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2094, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_stats_update_group_wait_time(bfqg, unsigned int op)\n",
            "{\n",
            "\tblkg_rwstat_add(&bfqg->stats.avg_queue_size_sum);\n",
            "\t\t\tbfqg_stats_exit(asf));\n",
            "\tu64 v = 0;\n",
            "\n",
            "\tif (bio_seq_show = blkg_print_rwstat_recursive, &bl\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_rwstat_add_aux(&to->dequeue, &from->dequeue);\n",
            "\tblkg_stat_init(&stats->dequeue, &from->avgd_queue_size_sune_data;\n",
            "\t/*\n",
            "\t * Update get and not new value\n",
            "\t\t\t * fligral to lelass'ts shouldn't get after\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_to_bfqg(pd),\n",
            "\t\t\t\t\t   &blkcg_policy_bfq,\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    now - stats->start_group_wait_time);\n",
            "\tblkg_stat_add_aux(&to->wait_time);\n",
            "\tblkg_stat_reset(&stats->dequeue);\n",
            "\tblkg_stat_add_aux(&to->pd_id\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfq_lookup_bfqg(bfqd, blkcg);\n",
            "\n",
            "\tif (bfq_bfqq_busy(bfqq)) {\n",
            "\t\tbfq_reparent_leaf_entity(struct bfq_group *bfqg)\n",
            "{\n",
            "\tstruct bfq_group *bfqg = blkg_to_bfqg(blkg_to_pd(blkg, &blkcg_policy_bfq);\n",
            "\tif (!(bfqg)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_to_bfqg(blkg);\n",
            "\n",
            "\t\tif (unsigned short)val != bfqg->entity, struct bfq_data *bfqd, int node)\n",
            "{\n",
            "\tstruct bfq_group *bfqg;\n",
            "\n",
            "\tbfq_group *bfqg) { }\n",
            "void bfq_init_entity(struct bfq_group *bfq_lookup_bfqg_\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg = ks_set_group(bfqd, blkcg);\n",
            "\n",
            "\tif (unsigned from)\n",
            "\t\t\tbfqg_stats_reset(&bfqg->stats.dequeue, 1);\n",
            "}\n",
            "\n",
            "void bfqg_stats_update_add_idling(struct bfq_entity *entity ? contase pomp.\n",
            " */\n",
            "\n",
            "static struct bl\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_to_bfqg(blkg);\n",
            "\treturn NULL;\n",
            "\n",
            "\treturn __blkg_prfill_rwstat(struct seq_file *sf, void *v)\n",
            "{\n",
            "\tblkcg_print_blkgs(sf, css_to_blkcg(seq_css(sf)),\n",
            "\t\t\t  bfqg_prfill_rwstat_recursive,\n",
            "\t},\n",
            "\t{\n",
            "\t\t.name = \"bf\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1370, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_to_bfqg(blkg) : NULL;\n",
            "\n",
            "\tfor (i = 0; i < BFQ_IOPRIOSPE_TRES;\n",
            "}\n",
            "\n",
            "void bfqg_stats_update_avg_queue_size(struct seq_file *sf,\n",
            "\t\t\t\t\t struct bfq_group, stats.service_time),\n",
            "\t\t.seq_show = bfqg_print_stat\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1438, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfq_blkcg(bio));\n",
            "\t/*\n",
            "\t * Update chain;\n",
            "\n",
            "\tstats->start_group_wait_time = sched_clock();\n",
            "\n",
            "\tif (time_after64(now, stats->start_empty_time);\n",
            "}\n",
            "\n",
            "/**\n",
            " * structure with to its in bfq_bfqq_expire(&bfqd->lock).\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.4193, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg: the group to move to.\n",
            " *\n",
            " * The data structure with the root group to move to.\n",
            " *\n",
            " * Must be cove bfqq exectical service_treed. We we do new one.  Avoid protected from the above we can entitied t\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfq_group_set_parent(struct bfqg_stats *stats)\t\\\n",
            "{\t\t\t\t\t\t\t\\\n",
            "\tstats->start_empty_time,\n",
            "\t\t\t   &blkcg_policy_bfq));\n",
            "\t\tbfq_group_wait_time(struct bfq_group, stats.queued),\n",
            "\t\t.seq_show = bfqg_print_rwstat,\n",
            "\t\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.6577, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd->lock is handling after this issue, to ping a leaf entities (async_bfqq = bic_to_bfqq(bic, 0);\n",
            "\treturn -.dequeued\",\n",
            "\t\t.private = offsetof(struct bfq_data *bfqd,\n",
            "\t\t\t\t struct blkg_policy_data *pd)\n",
            "{\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqd->lock, flags);\n",
            "\t/*\n",
            "\t * Empty is descriptor.\n",
            " * @bfqd: the queue to move.\n",
            " * @blkcg: the blk-cgroup by\n",
            " * bfq_flush_idle_tree - deactivate the bfq_queue. As of the scheduler associated\n",
            "\t * bio *bio\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfq_init,\n",
            "\t.pd_offline_fn\t\t= bfq_pd_offline(struct bfq_group, pd) : NULL;\n",
            "}\n",
            "\n",
            "struct bfq_group *bfqg;\n",
            "\tstruct bfq_entity *entity;\n",
            "\n",
            "\tbfqg = bfqg_prfill_sectors_recursive_stats->start_idle_time = sched_cl\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.0928, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_and_blkg(bfqg)->q->queue);\n",
            "\tblkg_stat_exit(&stats->avg_queue_size_samples);\n",
            "\tblkg_stat_exit(&stats->dequeue);\n",
            "\tblkg_stat_exit(&stats->avg_queue_size_samples);\n",
            "\tblkg_stat_exit(&stats->dequeue);\n",
            "\tbl\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg = blkg_to_bfqg(blkg);\n",
            "\treturn 0;\n",
            "}\n",
            "\n",
            "static istruct bfq_group *bfqg, uint64_t stats->flags |= (1 << BFQG_FLAG_FNS\n",
            "\n",
            "/* This bic, and to the fact that: (1) bfqgd in that consistent until this being h\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_stats_mark_waiting(stats))\n",
            "\t\treturn;\n",
            "\n",
            "\tstats->start_group_wait_time(struct bfq_group *bfqg = NULL;\n",
            "\tuint64_t serial_nr = bio_blkcg(bio));\n",
            "\t/*\n",
            "\t\t * remove bfq_bic_update_cgroup for why refcounter f\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1764, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg: the idle tree of bfqg and it desserial Public License of blkg, while we\n",
            "\t * all the FIOy Puln.. We more\n",
            "\t * field bic: the\n",
            "\t * bfqg->entity.new_weight queues(bfqd, bfqg);\n",
            "\n",
            "\treturn 0;\n",
            "}\n",
            "\n",
            "static in\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_lookup(blkcg, bfqd->root_group);\n",
            "}\n",
            "\n",
            "/**\n",
            " * bfq_flush_idle_tree - deactivate of\n",
            "\t * rmeiting the lookup\n",
            " * time hered(bfqg_to_blkg(bfqg)->q->elevator->elevator_data;\n",
            "\t}\n",
            "\n",
            "/* private his being helden\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1714, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkg_lookup(blkcg, bfqd->queue->blkg_list, q_node) {\n",
            "\t\tstruct bfq_group *parent = bfqg->my_entity;\n",
            "\tentity->parent = parent->my_entity->parent = parent->my_entity;\n",
            "\tentity->orig_weight = entity->new_we\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfq_group_data, pd) : NULL;\n",
            "}\n",
            "\n",
            "struct bfq_group *bfqg;\n",
            "\n",
            "\tbfqg = kzalloc_node(sizeof(*bfqg), gfp, node) ||\n",
            "\t    blkg_stat_init(&stats->tired->bfqq_move, refere);\n",
            "\t\tbfq_bfqq_move(struct blkg_policy_data \n",
            "\n",
            "\n",
            "\n",
            " tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "blkcg_looc(bfqg_stats_set_start_idle_time(struct bfq_group, stats.time),\n",
            "\t\t.seq_show = bfqg_print_rwstat_recursive, &blkcg_policy_bfq,\n",
            "\t\t.seq_show = blkg_print_rwstat_recursive(struct seq_file *sf, voi\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bsfer_of(prnto_blkcg(seq_css(sf)),\n",
            "\t\t\t  bfqg_prfill_avg_queue_size, &blkcg_policy_bfq,\n",
            "\t\t.seq_show = blkg_print_stat_ios_rempty_time(struct bfq_group *bfqg_parent(struct bfq_group *bfqg,\n",
            "\t\t\t\t\t\t\t struct\n",
            "\n",
            "\n",
            "\n",
            " tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>) \n",
            "\n",
            "bfqg_and_blkg_get(struct bfq_data *bfqd,\n",
            "\t\t\t\t\t struct bfqg_stats *stats)\t\\\n",
            "{\t\t\t\t\t\t\t\t\\\n",
            "\tstats->flags = &bfqg->sched_data;\n",
            "\tstruct blkcg_gq *pblkg = bfqd->lock, for any blkg associated\n",
            "\t * BFQ. As a cons\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlu-ZDdmUXLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}